# Progress!

### Some updates
Since last blog post, I tried to write another outlining some challenges I had been facing. However, I did not commit the changes before accidentally closing my tab. This is a lesson that I only need to learn once and will not be happening again. 

I have since got my Question 2 working! And am working on Question 3 as well as some final touches of Q2. 

### Question 2
The implementation of Q2 was not super difficult. It relied quite heavily on the "is-it-a-bird" example, but rather than classifying images into one of two categories, they were classified into one of ten, requiring more images to be downloaded. The largest caveat with this was the inconsistency of the DuckDuckGo function. For example, I completed a large amount of the question within the first week, but when I returned to my code, no images would download. Luckily, the following day my code ran again (with no changes), but in case this happens again, Brain also provided us with a solution. 

Q2 also required the use of confusion matrices and T-SNE plot for analysis purposes. I had never heard of T-SNE plots before but after some research I recognised them. Confusion matrices were new to me but were also introduced in another course at a similar time so I had a better understanding of these. Never the less both were quite interesting analysis techniques and possibly require their own blog posts. More to come. 

### Question 3
Q3 was a daunting task for me. I have not done much AI stuff before, so jumping from the FastAI intro notebook to using AI to identify real and fake images felt like a big jump. To start I looked on Kaggle for some inspiration and to have a look at how others were approaching this problem. Most were using CNNs. I had a quick google and noted that is what I was using in Q2! Crazy to think FastAI was so high level that I didnâ€™t realise I was already using CNNs. 
With this info from Kaggle, I ran my original Q2 code but with the new images and classes. This looked like it was going to take a while - so, taking some inspiration from "Gerry" on Kaggle, I used a subset of the images (how did I not think of that earlier?). To split up the data, I had chatgpt write me code to copy the first n images in a directory and put them in a new one for me. Using this new smaller data set, initially 200 images for training, I got a poor accuracy {%insert accuracy here%}, but increasing my set size also increased my accuracy as the model was better trained. I settled on using 20,000 images to train the model to ensure I had an accuracy that would replicate what I would get using 100,000 images for training - this gave me an accuracy of {this}. 

Here felt a good pace to stop - I had a good accuracy for Q3 without doing too much work and now I needed to research some other ways to improve it. 

## Conclusions
Good progress on both Q2 and Q3. There should be new posts coming of confusion matrices and T-SNEs as well as updates on improving Q3.
